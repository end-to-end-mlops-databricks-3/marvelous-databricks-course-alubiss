# This is a Databricks asset bundle definition for marvelous-databricks-course-alubiss.
# The Databricks extension requires databricks.yml configuration file.
# See https://docs.databricks.com/dev-tools/bundles/index.html for documentation.

bundle:
  name: marvelous-databricks-course-alubiss

include:
  - bundle_monitoring.yml
# - resources/*.yml

artifacts:
  default:
    type: whl
    build: uv build
    path: .

variables:
  git_sha:
    description: git_sha
    default: abcd
  repo:
    description: repo name
    default: marvelous-databricks-course-alubiss
  org:
    description: GitHub organization
    default: end-to-end-mlops-databricks-3
  branch:
    description: branch
    default: main
  schedule_pause_status:
    description: schedule pause status
    default: PAUSED
  is_test:
    default: 1
  env:
    description: environment
    default: dev
  marvelous_version:
    description: version of Marvelous package
    default: "0.3.1"
  package_version:
    description: version of private package
    default: "031"

resources:
  jobs:
    deployment:
      name: ${bundle.name}-workflow-${var.branch}
      parameters:
        - name: is_test
          default: 1
      schedule:
        quartz_cron_expression: "0 0 6 ? * MON"
        timezone_id: "Europe/Amsterdam"
        pause_status: ${var.schedule_pause_status}
      tags:
        project_name: "hotel-reservations"
      job_clusters:
        - job_cluster_key: "hotel-reservations-cluster"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            data_security_mode: "SINGLE_USER"
            node_type_id: "r3.xlarge"
            driver_node_type_id: "r3.xlarge"
            autoscale:
              min_workers: 1
              max_workers: 1
            spark_env_vars:
              "TOKEN_STATUS_CHECK": "{{secrets/mlops_course/git_token_status_check}}"
      tasks:
        - task_key: "preprocessing"
          job_cluster_key: "hotel-reservations-cluster"
          spark_python_task:
            python_file: "scripts/01.process_data.py"
            parameters:
              - "data_ingestion"
              - "--root_path"
              - "${workspace.root_path}"
              - "--env"
              - "${var.env}"
              - "--is_test"
              - "{{job.parameters.is_test}}"
          libraries:
            - whl: ./dist/*.whl
            - whl: /Volumes/mlops_prd/utils/package/marvelous-${var.marvelous_version}-py3-none-any.whl
        - task_key: "train_model"
          job_cluster_key: "hotel-reservations-cluster"
          depends_on:
            - task_key: "preprocessing"
          spark_python_task:
            python_file: "scripts/02.train_register_model_pipeline.py"
            parameters:
              - "model_train_register"
              - "--root_path"
              - "${workspace.root_path}"
              - "--env"
              - "${var.env}"
              - "--git_sha"
              - "${var.git_sha}"
              - "--job_run_id"
              - "{{job.run_id}}"
              - "--branch"
              - "${var.branch}"
              - "--is_test"
              - "{{job.parameters.is_test}}"
          libraries:
            - whl: ./dist/*.whl
            - whl: /Volumes/mlops_prd/utils/package/marvelous-${var.marvelous_version}-py3-none-any.whl
        - task_key: model_updated
          condition_task:
            op: "EQUAL_TO"
            left: "{{tasks.train_model.values.model_updated}}"
            right: "1"
          depends_on:
            - task_key: "train_model"
        - task_key: "deploy_model"
          depends_on:
            - task_key: "model_updated"
              outcome: "true"
          job_cluster_key: "hotel-reservations-cluster"
          spark_python_task:
            python_file: "scripts/03.deploy_model.py"
            parameters:
              - "deployment"
              - "--root_path"
              - "${workspace.root_path}"
              - "--env"
              - "${var.env}"
              - "--is_test"
              - "{{job.parameters.is_test}}"
          libraries:
            - whl: ./dist/*.whl
            - whl: /Volumes/mlops_prd/utils/package/marvelous-${var.marvelous_version}-py3-none-any.whl
        - task_key: post_commit_status_required
          condition_task:
            op: "EQUAL_TO"
            left: "{{job.parameters.is_test}}"
            right: "1"
          depends_on:
            - task_key: "deploy_model"
        - task_key: "post_commit_status"
          depends_on:
            - task_key: "post_commit_status_required"
              outcome: "true"
          job_cluster_key: "hotel-reservations-cluster"
          spark_python_task:
            python_file: "scripts/04.post_commit_status.py"
            parameters:
              - "post_commit_check"
              - "--job_run_id"
              - "{{job.run_id}}"
              - "--job_id"
              - "{{job.id}}"
              - "--git_sha"
              - "${var.git_sha}"
              - "--repo"
              - "${var.repo}"
              - "--org"
              - "${var.org}"
          libraries:
            - whl: ./dist/*.whl
            - whl: /Volumes/mlops_prd/utils/package/marvelous-${var.marvelous_version}-py3-none-any.whl

    model_by_country:
      name: ${bundle.name}-model-by-country
      parameters:
        - name: country
          default: "PL"
      schedule:
        quartz_cron_expression: "0 0 6 ? * MON"
        timezone_id: "Europe/Amsterdam"
        pause_status: ${var.schedule_pause_status}
      tags:
        project_name: "hotel-reservations"
      job_clusters:
        - job_cluster_key: "hotel-reservations-cluster"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            data_security_mode: "SINGLE_USER"
            node_type_id: "r3.xlarge"
            driver_node_type_id: "r3.xlarge"
            autoscale:
              min_workers: 1
              max_workers: 1
            spark_env_vars:
              "TOKEN_STATUS_CHECK": "{{secrets/mlops_course/git_token_status_check}}"
      tasks:
        - task_key: "preprocessing"
          job_cluster_key: "hotel-reservations-cluster"
          spark_python_task:
            python_file: "scripts/06a.process_data_by_country.py"
            parameters:
              - "common"
              - "--root_path"
              - "${workspace.root_path}"
              - "--env"
              - "${var.env}"
              - "--country"
              - "{{job.parameters.country}}"
          libraries:
            - whl: ./dist/*.whl
            - whl: /Volumes/mlops_prd/utils/package/marvelous-${var.marvelous_version}-py3-none-any.whl
        - task_key: "train_model"
          job_cluster_key: "hotel-reservations-cluster"
          depends_on:
            - task_key: "preprocessing"
          spark_python_task:
            python_file: "scripts/06b.train_register_model_by_country.py"
            parameters:
              - "common"
              - "--root_path"
              - "${workspace.root_path}"
              - "--env"
              - "${var.env}"
              - "--country"
              - "{{job.parameters.country}}"
          libraries:
            - whl: ./dist/*.whl
            - whl: /Volumes/mlops_prd/utils/package/marvelous-${var.marvelous_version}-py3-none-any.whl

    new_job:
      name: ${bundle.name}-process-countries
      tasks:
      - task_key: process_modelling
        for_each_task:
          inputs: '["PL", "UK"]'
          concurrency: 2
          task:
            task_key: Prep_models_iteration
            run_job_task:
              job_id: ${resources.jobs.model_by_country.id}
              job_parameters:
                country: "{{input}}"
      queue:
        enabled: true

  # apps:
  #   inference_app:
  #     name: model_application${var.package_version}
  #     source_code_path: ./app
  #     description: "A Streamlit app for ML inference on Databricks"

targets:
  dev:
    cluster_id: 0507-194506-ye56mzn8 #replace with your own!
    default: true
    mode: development
    workspace:
      host: https://dbc-c2e8445d-159d.cloud.databricks.com
      root_path: /Workspace/Users/${workspace.current_user.userName}/.bundle/${bundle.target}/${bundle.name}
    variables:
      schedule_pause_status: PAUSED
      is_test: 1
      env: dev
    artifacts:
      default:
        type: whl
        build: uv build
        path: .
        dynamic_version: True

  test:
    presets:
      name_prefix: 'test_'
    workspace:
      host: https://dbc-c2e8445d-159d.cloud.databricks.com
      root_path: /Shared/.bundle/${bundle.target}/${bundle.name}
    variables:
      schedule_pause_status: PAUSED
      is_test: 1
      env: dev

  acc:
    presets:
      name_prefix: 'acceptance_'
    workspace:
      host: https://dbc-c2e8445d-159d.cloud.databricks.com
      root_path: /Shared/.bundle/${bundle.target}/${bundle.name}
    variables:
      schedule_pause_status: PAUSED
      is_test: 1
      env: acc

  prd:
    mode: production
    workspace:
      host: https://dbc-c2e8445d-159d.cloud.databricks.com
      root_path: /Shared/.bundle/${bundle.target}/${bundle.name}
    variables:
      schedule_pause_status: PAUSED # normally UNPAUSED
      is_test: 0
      env: prd

# Optionally, there could be 'staging' or 'prod' targets here.
# prod:
#   workspace:
#     host: https://dbc-c2e8445d-159d.cloud.databricks.com
